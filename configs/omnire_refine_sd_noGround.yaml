seed: 0
dataset: waymo/3cams
# ------------- Trainer ------------ #
trainer:
  type: models.trainers.MultiTrainer
  optim:
    num_iters: 30000
    use_grad_scaler: false
    cache_buffer_freq: -1 # if > 0, use error based image sampler for training
  render:
    near_plane: 0.1 # near plane for rendering
    far_plane: 10000000000.0 # far plane for rendering
    antialiased: false # whether to use antialiasing for gaussian rendering, supported by gsplat kernel
    packed: false # whether to use packed rendering, supported by gsplat kernel
    absgrad: true # whether to use absolute gradient for rendering, supported by gsplat kernel
    sparse_grad: false # whether to use sparse gradient for rendering, supported by gsplat kernel
    batch_size: 1 # batch size for rendering, currently only support 1
  losses:
    rgb:
      #w: 0.8
      w: 1.2
    ssim:
      #w: 0.2
      w: 1.0
    mask:
      # #w: 0.05
      # w: 0.2
      opacity_loss_type: bce # choose from [bce, safe_bce]
      sky:
        #w: 0.05
        w: 0.2
      background: # accumulated opacity should be close 0 at road_mask and sky_mask, otherwise 1.
        w: 0.2
      ground: # accumulated opacity should be close to 1 within road_mask, 0 elsewhere.
        w: 0.2
    depth:
      w: 0.01 # weight of depth loss
      inverse_depth: False # whether to use inverse depth, NOTE that when set to True, must normalize=True
      normalize: False # whether to normalize depth loss
      loss_type: l1 # choose from ["l1", "l2"]
    affine:
      w: 0.00001 # weight of affine regularization
  res_schedule:
    double_steps: 250 # training starts at 1/d resolution, every n steps this is doubled
    downscale_times: 2 # at the beginning, resolution is 1/2^d, where d is this number
  gaussian_optim_general_cfg:
    xyz:
      lr: 1.6e-04
      lr_final: 1.6e-06
      scale_factor: scene_radius # str or float, if "scene_scale", scale the learning rate by the scene scale
    sh_dc:
      lr: 0.0025
    sh_rest:
      lr: 0.000125
    opacity:
      #lr: 0.05
      lr: 0.01
    scaling:
      #lr: 0.005
      lr: 0.001
    rotation:
      lr: 0.001
  gaussian_ctrl_general_cfg:
    warmup_steps: 500             # warmup steps for alpha
    reset_alpha_interval: 3000    # reset alpha every n steps
    refine_interval: 100          # refine gaussians every n steps
    sh_degree_interval: 1000      # every n intervals turn on another sh degree
    n_split_samples: 2            # number of samples to split gaussians into
    # may differ in different models
    reset_alpha_value: 0.01       # reset alpha to this value
    densify_grad_thresh: 0.002
    densify_size_thresh: 0.0005
    cull_alpha_thresh: 0.005      # threshold of opacity for culling gaussians
    cull_scale_thresh: 0.5        # threshold of scale for culling gaussians
    cull_screen_size: 0.15        # if a gaussian is more than this percent of screen space, cull it
    split_screen_size: 0.05       # if a gaussian is more than this percent of screen space, split it
    stop_screen_size_at: 4000     # stop culling/splitting at this step WRT screen size of gaussians
    stop_split_at: 15000          # stop splitting at this step
    sh_degree: 3                  # sh degree for gaussians

# ------------- Model ------------ #
model:
  Background:
    type: models.gaussians.VanillaGaussians
    init:
      from_lidar:
        num_samples: 8_000_000
        return_color: True
      near_randoms: 200_000
      far_randoms: 1_000_000
    reg:
      sharp_shape_reg:
        w: 1.
        step_interval: 10
        max_gauss_ratio: 5       # threshold of ratio of gaussian max to min scale before applying regularization loss from the PhysGaussian paper

  RigidNodes:
    type: models.nodes.RigidNodes
    init:
      instance_max_pts: 5000 # max initial points for each instance
      only_moving: true # only optimize moving instances
      traj_length_thres: 1.0 # threshold of trajectory length for moving instances
    ctrl:
      reset_alpha_value: 0.1
      cull_scale_thresh: 0.25
      sh_degree: 1
      cull_out_of_bound: true
    reg:
      sharp_shape_reg:
        w: 1.
        step_interval: 10
        max_gauss_ratio: 10.
      temporal_smooth_reg:
        trans:
          w: 0.01 # optimal value may vary
          smooth_range: 5 # no ablation
    optim:
      ins_rotation:
        lr: 0.00001
        lr_final: 0.000005
      ins_translation:
        lr: 0.0005
        lr_final: 0.0001
  Sky:
    type: models.modules.EnvLight
    params:
      resolution: 1024
    optim:
      all:
        lr: 0.01
  Affine:
    type: models.modules.AffineTransform
    params:
      embedding_dim: 4
      base_mlp_layer_width: 64
      pixel_affine: False
    optim:
      all:
        lr: 1.0e-5
        weight_decay: 1.0e-6
  CamPose:
    type: models.modules.CameraOptModule
    optim:
      all:
        lr: 1.0e-5
        weight_decay: 1.0e-6

multi_gpu:
  use_model_parallel: True
sd_pipeline_flag: True
generative_engine:
  type: reconic.models.generative_models.SD15_GaussianFixModel
  scheduler: reconic.engines.GenerativeScheduler
  base_model_id: /root/autodl-tmp/LCM-runwayml-stable-diffusion-v1-5
  # pretrained_unet_weights: /data/shared/pretrained_models/sd_repair/model.safetensors
  groundingdino_model_id: /root/autodl-tmp/GroundingDINO/
  sam_model_id: /root/autodl-tmp/sam-vit-huge/
  bert_model_id: /root/autodl-tmp/bert-base-uncased/

  training_batch_size: 4
  inference_batch_size: 4
  use_8bit_optimizer: True
  dst_size: [304, 480]
  # dst_size: [600, 960]
  num_inference_steps: 20
  image_guidance_scale: -1
  guidance_scale: -1

joint_training_cfg:
  start_engine_train_at: 500
  stop_engine_train_at: 15000
  start_engine_infer_at: 15000
  max_shift: 3
  iterations_per_shift: 2000

# ------------- render ------------ #
render:
  fps: 10 # frames per second for the main rendered output
  render_full: True # whether to render full resolution videos
  render_test: True # whether to render test set
  render_novel: 
    traj_types:
    - type: relative_lane_shift
      direction: x
      distance: 1.5
      render_name: lane_shift_left_1.5m
    - type: relative_lane_shift
      direction: x
      distance: 3.0
      render_name: lane_shift_left_3m
      # - front_center_interp # type of trajectory for novel view synthesis
    fps: 10 # frames per second for novel view rendering
  vis_lidar: False # whether to visualize lidar points on ground truth images
  vis_sky: False # whether to include "rgb_sky" and "rgb_sky_blend" in rendered keys
  vis_error: False # whether to include "rgb_error_map" in rendered keys

# ------------- logging ------------ #
logging:
  vis_freq: 500 # how often to visualize training stats
  print_freq: 500 # how often to print training stats
  saveckpt_freq: 15000 # how often to save checkpoints
  save_seperate_video: True # whether to save seperate videos for each scene

